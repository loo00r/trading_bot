625/625 [==============================] - 4s 6ms/step - loss: 8.6191e-05
L2 Regularization (λ=0.0005): Validation Loss=3.80899800802581e-05
L2 Regularization (λ=0.001): Validation Loss=4.405171421240084e-05
L2 Regularization (λ=0.01): Validation Loss=8.619088475825265e-05


Додайте шари уваги (Attention layers) до вашої моделі.


from sklearn.model_selection import RandomizedSearchCV
   from keras.wrappers.scikit_learn import KerasRegressor
   from keras.models import Sequential
   from keras.layers import LSTM, Dense, Dropout

   def create_model(units=50, dropout_rate=0.2, optimizer='adam'):
       model = Sequential([
           LSTM(units, return_sequences=True, input_shape=(seq_length, n_features)),
           Dropout(dropout_rate),
           LSTM(units),
           Dropout(dropout_rate),
           Dense(pred_length)
       ])
       model.compile(optimizer=optimizer, loss='mse')
       return model

   # Define the parameter space
   param_dist = {
       'units': [32, 64, 128],
       'dropout_rate': [0.1, 0.2, 0.3],
       'optimizer': ['adam', 'rmsprop'],
       'batch_size': [16, 32, 64],
       'epochs': [50, 100, 150]
   }

   # Wrap the model
   model = KerasRegressor(build_fn=create_model, verbose=0)

   # Random search
   random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, 
                                      n_iter=20, cv=3, verbose=2, n_jobs=-1)

   # Fit the random search
   random_search.fit(X_train, y_train)

   # Get the best parameters
   best_params = random_search.best_params_
   print("Best parameters:", best_params)


Ансамблеві методи:

Створіть ансамбль моделей, комбінуючи прогнози кількох різних моделей (наприклад, LSTM, Prophet, ARIMA).
Використовуйте методи стекінгу або блендингу для об'єднання прогнозів.

Валідація та оцінка моделі:

Використовуйте технік walk-forward validation для більш реалістичної оцінки продуктивності моделі.
Розгляньте додаткові метрики, такі як MAPE або RMSE, для оцінки якості прогнозів.

Обробка довгострокових залежностей:

Якщо ваші дані мають довгострокові залежності, розгляньте використання моделей з довгою пам'яттю, таких як Transformer або Temporal Convolutional Networks (TCN).


Інтерпретація моделі:

Використовуйте методи інтерпретації моделі, такі як SHAP (SHapley Additive exPlanations), щоб зрозуміти, які фактори найбільше впливають на прогнози.


Регуляризація:

Експериментуйте з різними методами регуляризації (L1, L2, Dropout) для запобігання перенавчання.



Передбачення можливо потрібно робити не чисто 5 свічей а волюм між мін і макс на наступні 5 свічей

I will dodge high volatility in base model, then will create volatility model for tracking hight volatility moments

Probably I will use only differences beetween different values

High and low features should be removed!!!

Probably we will predict differences beetween high and low value of the candle

Also I think I will use 2 models one for the differences beetween high and low value 
and the second one for the changes beetween open and close in percentage

In feature I will add some timers for check every opened positions

Backtesting libraries: freqtrade, btgym, zipline, backtrader

Probably it will be third neural network that predict close value for the first candle

Probably it will structure like this ( ensemble model): one model that predict movement
beetween close values( +100, +20, -40),
second model will just about trend movement

Bot will make order based on on highest differences

In future it will be LLM model that will take all the info before the order and make decision